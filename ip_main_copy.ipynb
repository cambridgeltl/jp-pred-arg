{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bp_pas.params as params\n",
    "import bp_pas.corpus as corpus\n",
    "import bp_pas.stats as stats\n",
    "from bp_pas.eval import evaluate\n",
    "\n",
    "import sys\n",
    "import gflags\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.load_defaults()\n",
    "flags = gflags.FLAGS\n",
    "arg_str = '' #'--train_data single.utf8 --dev_data single.utf8 --test_data single.utf8'\n",
    "args = [''] + arg_str.split(' ')\n",
    "argv = flags(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tmp params to add to flags\n",
    "unk_threshold = 10\n",
    "unk_token = '<UNK>'\n",
    "arg_embedding_size = 32\n",
    "pred_embedding_size = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/NTC_1.5/processed/train.utf8\n",
      "1 train sentences.\n",
      "1 test sentences.\n",
      "1 dev sentences.\n",
      "\n",
      "CORPUS STATISTICS\n",
      "\tDocs: 1  Sents: 41005  Words: 1048292\n",
      "\tPredicates: 117565  Arguments 181613\n",
      "\n",
      "\n",
      "\n",
      "CASE DISTRIBUTION\n",
      "\tGa\tBST: 357  DEP: 63280  INTRA-ZERO: 21328  INTER-ZERO: 0  EXOPHORA: 0\n",
      "\tO\tBST: 283  DEP: 41807  INTRA-ZERO: 3398  INTER-ZERO: 0  EXOPHORA: 0\n",
      "\tNi\tBST: 786  DEP: 13807  INTRA-ZERO: 1034  INTER-ZERO: 0  EXOPHORA: 0\n",
      "\n",
      "\tPredicates: 106708\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "print(flags.train_data)\n",
    "ntc = corpus.NTCLoader()\n",
    "train_data = ntc.load_corpus(flags.train_data, flags.max_train_instances)\n",
    "test_data  = ntc.load_corpus(flags.test_data, flags.max_train_instances)\n",
    "dev_data   = ntc.load_corpus(flags.dev_data, flags.max_train_instances)\n",
    "print('{} train sentences.'.format(len(train_data)))\n",
    "print('{} test sentences.'.format(len(test_data)))\n",
    "print('{} dev sentences.'.format(len(dev_data)))\n",
    "stats.corpus_statistics(train_data)\n",
    "stats.show_case_dist(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "class Vocab:\n",
    "    \n",
    "    def __init__(self, init_words=[], unk_token = '<UNK>', unk_threshold=10):\n",
    "        self.word2int = {}\n",
    "        self.int2word = []\n",
    "        self.frozen = False\n",
    "        self.add(unk_token)\n",
    "        if len(init_words) > 0:\n",
    "            self.build(init_words, unk_threshold)\n",
    "\n",
    "    def add(self, elem):\n",
    "        assert not self.frozen\n",
    "        if elem not in self.word2int:\n",
    "            self.int2word.append(elem)\n",
    "            self.word2int[elem] = len(self) - 1\n",
    "    \n",
    "    def build(self, words, unk_threshold=10):\n",
    "        counter = Counter()\n",
    "        for w in words:\n",
    "            counter[w] += 1\n",
    "        for w,c in counter.items():\n",
    "            if c > unk_threshold:\n",
    "                self.add(w)\n",
    "    \n",
    "    def freeze(self):\n",
    "        self.frozen = True\n",
    "\n",
    "    def index(self, elem):\n",
    "        if self.frozen and elem not in self.word2int:\n",
    "            return 0\n",
    "        else:\n",
    "            assert elem in self.word2int\n",
    "            return self.word2int[elem]\n",
    "    \n",
    "    def word(self, index):\n",
    "        assert index < self.int2word\n",
    "        return self.int2word[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.int2word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting all tokens...\n",
      "Total tokens: 1783582\n",
      "\n",
      "Building (argument) vocabulary...\n",
      "Vocabulary size: 10676\n",
      "\n",
      "Collecting predicates...\n",
      "Number of predicates: 2530\n",
      "\n",
      "Collecting argument types...\n",
      "Arg types:  ['NIL', 'O', 'NI', 'GA']\n"
     ]
    }
   ],
   "source": [
    "# Setup vocabulary\n",
    "all_sents = train_data[0] + test_data[0] + dev_data[0]\n",
    "\n",
    "\n",
    "print('Collecting all tokens...')\n",
    "word_tokens = list(word.form\n",
    "                   for sent in all_sents\n",
    "                   for word in sent)\n",
    "print('Total tokens: {}\\n'.format(len(word_tokens)))\n",
    "\n",
    "print('Building (argument) vocabulary...')\n",
    "arg_vocab = Vocab(init_words=word_tokens, \n",
    "                  unk_token=unk_token, \n",
    "                  unk_threshold=unk_threshold)  #[unk_token] + get_vocab(word_tokens)\n",
    "arg_vocab.freeze()\n",
    "arg_vocabulary_size = len(arg_vocab)\n",
    "print('Vocabulary size: {}\\n'.format(arg_vocabulary_size))\n",
    "\n",
    "print('Collecting predicates...')\n",
    "pred_vocab = Vocab(init_words=[word.form\n",
    "                               for sent in all_sents\n",
    "                               for word in sent if word.is_prd])\n",
    "pred_vocab.freeze()\n",
    "pred_vocabulary_size = len(pred_vocab)\n",
    "print('Number of predicates: {}\\n'.format(pred_vocabulary_size))\n",
    "\n",
    "print('Collecting argument types...')\n",
    "arg_types = ['NIL'] + list(set([arg.arg_type \n",
    "                      for sent in all_sents \n",
    "                      for pas in sent.pas\n",
    "                      for arg in pas.args]))\n",
    "#for sent in train_data[0]:\n",
    "#    for pas in sent.pas:\n",
    "#        print(pas.pred.word_index)\n",
    "#        for arg in pas.args:\n",
    "#            print(arg)\n",
    "print('Arg types: ', arg_types)\n",
    "num_types = len(arg_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data structures into numpy ndarrays for placeholders\n",
    "def sent2nump(sent):\n",
    "    sent_ids = [arg_vocab.index(w.form) for w in sent]\n",
    "    pases = [w.form for w in sent if w.is_prd]\n",
    "    pred_ids = [pred_vocab.index(w.form) for w in sent if w.is_prd]\n",
    "#    print(pas_ids)\n",
    "#    print(pases)\n",
    "    label_mats = []\n",
    "    for pas in sent.pas:\n",
    "        lm = label_matrix(pas, arg_types, len(sent))\n",
    "        label_mats.append(lm)\n",
    "    lm = np.concatenate(label_mats, axis=1) #.shape\n",
    "    return [sent_ids], [pred_ids], lm\n",
    "#        break\n",
    "\n",
    "def label_matrix(pas, arg_types, sent_len):\n",
    "    zeros = np.zeros((len(arg_types), sent_len))\n",
    "    for arg in pas.args:\n",
    "        zeros[arg_types.index(arg.arg_type), arg.word_index] = 1.0\n",
    "    for j in range(sent_len):\n",
    "        found = False\n",
    "        for i in range(1, len(arg_types)):\n",
    "            if zeros[i, j] == 1.0:\n",
    "                found = True\n",
    "        if not found:\n",
    "            zeros[0,j] = 1.0\n",
    "    return zeros\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#def pas2matrix(pas):\n",
    "    \n",
    "\n",
    "def sent2ints(sent):\n",
    "    sent_ids = [vocab.index(w.form) for w in sent]\n",
    "    pas_ids = []\n",
    "    return sent_ids, pas_ids\n",
    "\n",
    "#def sents2batch(sents, vocab, batch_size):\n",
    "#    for sent in sents:\n",
    "#\n",
    "#    int_sents = [ for sent in train_data[0]]\n",
    "#    return np.array([int_sents[0]]), np.array([int_sents[0]])\n",
    "\n",
    "\n",
    "#sents, labels = sents2batch(train_data, vocab, batch_size=1)\n",
    "#print(batched_sent_dicts.shape)\n",
    "\n",
    "d = train_data[0][0]\n",
    "#print(len(d))\n",
    "#print(' '.join([w.form for w in d.words]))\n",
    "#for w in d:\n",
    "#    if w.is_prd:\n",
    "#        print(w, '\\t', w.arg_types, '\\t  ', w.arg_indices)\n",
    "#sent2nump(d)\n",
    "\n",
    "#GA_INDEX = 0\n",
    "#O_INDEX = 1\n",
    "#NI_INDEX = 2\n",
    "\n",
    "# pred id 10 has NI and GA\n",
    "# pred id 25 has GA and O\n",
    "# pred id 31 has GA\n",
    "\n",
    "train_dicts = [sent2nump(td) for td in train_data[0][1:5]]\n",
    "#sent_ids, pred_ids = sent2nump(train_data[0][0])\n",
    "#print(sent_ids)\n",
    "#print(pred_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the context embedding\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Construct embedding matrix for contex/arguments\n",
    "arg_embeddings = tf.Variable(tf.random_uniform([arg_vocabulary_size, arg_embedding_size], -1.0, 1.0, dtype=tf.float64))\n",
    "\n",
    "# Construct embedding matrix for predicates\n",
    "pred_embeddings = tf.Variable(tf.random_uniform([pred_vocabulary_size, num_types * pred_embedding_size], -1.0, 1.0, dtype=tf.float64))\n",
    "\n",
    "# Setup placeholders\n",
    "batch_size = 1\n",
    "sent_placeholder = tf.placeholder(tf.int32, shape=(batch_size, None))\n",
    "pred_placeholder = tf.placeholder(tf.int32, shape=(batch_size, None))\n",
    "gold_placeholder = tf.placeholder(tf.float64, shape=(num_types, None))\n",
    "\n",
    "def context_embeddings(sent, arg_embeddings, output_dim):\n",
    "    # Shape [batch_size, max_sent_len, emb_dim]\n",
    "    embed_rep = tf.gather(arg_embeddings, sent)\n",
    "    # List of length max_sent_len, comprising [batch_size, emb_dim] tensors\n",
    "#    X = tf.unstack(embed_rep, axis=1, num=72)\n",
    "#    return X\n",
    "    X = embed_rep\n",
    "#    return X\n",
    "    fw_cell = tf.contrib.rnn.LSTMCell(num_units=output_dim/2, state_is_tuple=True)\n",
    "    bw_cell = tf.contrib.rnn.LSTMCell(num_units=output_dim/2, state_is_tuple=True)\n",
    "    outputs, states  = tf.nn.bidirectional_dynamic_rnn(\n",
    "        cell_fw=fw_cell,\n",
    "        cell_bw=bw_cell,\n",
    "        dtype=tf.float64,\n",
    "#        sequence_length=X_lengths,\n",
    "        inputs=X)\n",
    "    output_fw, output_bw = outputs\n",
    "    states_fw, states_bw = states\n",
    "    final_rep = tf.concat(outputs, 2)\n",
    "    return final_rep\n",
    "\n",
    "\n",
    "def pred_full_scoring(preds, pred_embeddings, context_mat):\n",
    "    # Reshape the context mat to remove the batch dim\n",
    "    context_tensor = tf.reshape(context_mat, shape=[-1, tf.shape(context_mat)[-1]])\n",
    "\n",
    "    # Shape [batch_size, num_tokens, pred_embed_dim]\n",
    "    # actually ,remove batch for now\n",
    "    pred_mat = tf.gather(pred_embeddings, preds)\n",
    "    pred_mat = tf.squeeze(pred_mat)\n",
    "\n",
    "    # Split the pred embeddings into individual pred tensors\n",
    "    score_tensor = tf.map_fn(lambda x: scoring(x, context_tensor), pred_mat)\n",
    "    \n",
    "    # Reshape score tensor for loss tensor\n",
    "    score_tensor = tf.transpose(tf.reshape(score_tensor, shape=[-1, tf.shape(score_tensor)[-1]]))\n",
    "    return score_tensor\n",
    "\n",
    "\n",
    "def scoring(pred_tensor, context_tensor):\n",
    "#    pred_tensor = tf.reshape(pred_tensor, shape=[1, -1, 4])\n",
    "    pred_tensor = tf.reshape(pred_tensor, shape=[tf.shape(context_tensor)[-1], -1])\n",
    "    return tf.matmul(context_tensor, pred_tensor)\n",
    "\n",
    "#def pred_single_scoring(single_pred_set, single_context, num_slots, num_preds):\n",
    "#    return single_pred_set\n",
    "#    single_pred = tf.unstack(single_pred_set, num=num_preds)[0]\n",
    "#    return tf.transpose(single_pred)\n",
    "#    return tf.matmul(single_context, tf.transpose(single_pred))\n",
    "\n",
    "def srl_loss(gold, preds, pred_embeddings, context_mat):\n",
    "    prediction = pred_full_scoring(pred_placeholder, pred_embeddings, context_rep)\n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=tf.traspose(prediction), \n",
    "                                                   labels=tf.transpose(gold))\n",
    "    return loss\n",
    "\n",
    "context_rep = context_embeddings(sent_placeholder, arg_embeddings, output_dim=8)\n",
    "pred_scores = pred_full_scoring(pred_placeholder, pred_embeddings, context_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"Placeholder:0\", shape=(1, ?), dtype=int32) is not an element of this graph.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    929\u001b[0m             subfeed_t = self.graph.as_graph_element(subfeed, allow_tensor=True,\n\u001b[0;32m--> 930\u001b[0;31m                                                     allow_operation=False)\n\u001b[0m\u001b[1;32m    931\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2413\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2414\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2492\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2493\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2494\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor Tensor(\"Placeholder:0\", shape=(1, ?), dtype=int32) is not an element of this graph.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-343-b42b995084fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-343-b42b995084fe>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(sess, instance)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0msent_placeholder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msent_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mpred_placeholder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpred_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mgold_placeholder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgold_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     })\n\u001b[1;32m     12\u001b[0m     \u001b[0mpred_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_prd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    931\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             raise TypeError('Cannot interpret feed_dict key as Tensor: '\n\u001b[0;32m--> 933\u001b[0;31m                             + e.args[0])\n\u001b[0m\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"Placeholder:0\", shape=(1, ?), dtype=int32) is not an element of this graph."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "   0: 2.84\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      " 100: 0.72\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      " 200: 0.49\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      " 300: 0.42\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      " 400: 0.39\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      " 500: 0.36\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      " 600: 0.33\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      " 700: 0.31\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      " 800: 0.29\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      " 900: 0.27\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "1000: 0.25\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "1100: 0.23\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "1200: 0.22\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "1300: 0.21\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "1400: 0.19\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "1500: 0.18\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "1600: 0.17\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "1700: 0.17\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "1800: 0.16\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "1900: 0.15\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "2000: 0.14\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "2100: 0.14\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "2200: 0.13\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "2300: 0.13\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "2400: 0.13\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "2500: 0.12\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "2600: 0.12\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "2700: 0.11\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "2800: 0.11\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "2900: 0.11\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "3000: 0.10\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "3100: 0.10\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "3200: 0.10\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "3300: 0.10\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "3400: 0.09\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "3500: 0.09\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "3600: 0.09\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "3700: 0.09\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "3800: 0.09\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "3900: 0.08\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "4000: 0.08\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "4100: 0.08\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "4200: 0.08\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "4300: 0.08\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "4400: 0.08\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "4500: 0.07\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "4600: 0.07\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "4700: 0.07\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "4800: 0.07\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "4900: 0.07\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "5000: 0.07\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "5100: 0.07\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "5200: 0.07\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "5300: 0.07\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "5400: 0.06\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "5500: 0.06\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "5600: 0.06\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "5700: 0.06\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "5800: 0.06\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "5900: 0.06\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "6000: 0.06\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "6100: 0.06\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "6200: 0.06\n",
      "Prec = (0/60) = 0.0\n",
      "Rec  = (0/15) = 0.0\n",
      "6300: 0.06\n",
      "Prec = (5/60) = 8.333333333333334\n",
      "Rec  = (5/15) = 33.333333333333336\n",
      "6400: 0.06\n",
      "Prec = (5/60) = 8.333333333333334\n",
      "Rec  = (5/15) = 33.333333333333336\n",
      "6500: 0.06\n",
      "Prec = (5/60) = 8.333333333333334\n",
      "Rec  = (5/15) = 33.333333333333336\n",
      "6600: 0.05\n",
      "Prec = (5/60) = 8.333333333333334\n",
      "Rec  = (5/15) = 33.333333333333336\n",
      "6700: 0.05\n",
      "Prec = (5/60) = 8.333333333333334\n",
      "Rec  = (5/15) = 33.333333333333336\n",
      "6800: 0.05\n",
      "Prec = (5/60) = 8.333333333333334\n",
      "Rec  = (5/15) = 33.333333333333336\n",
      "6900: 0.05\n",
      "Prec = (5/60) = 8.333333333333334\n",
      "Rec  = (5/15) = 33.333333333333336\n",
      "7000: 0.05\n",
      "Prec = (5/60) = 8.333333333333334\n",
      "Rec  = (5/15) = 33.333333333333336\n",
      "7100: 0.05\n",
      "Prec = (5/60) = 8.333333333333334\n",
      "Rec  = (5/15) = 33.333333333333336\n",
      "7200: 0.05\n",
      "Prec = (5/60) = 8.333333333333334\n",
      "Rec  = (5/15) = 33.333333333333336\n",
      "7300: 0.05\n",
      "Prec = (5/60) = 8.333333333333334\n",
      "Rec  = (5/15) = 33.333333333333336\n",
      "7400: 0.05\n",
      "Prec = (5/60) = 8.333333333333334\n",
      "Rec  = (5/15) = 33.333333333333336\n",
      "7500: 0.05\n",
      "Prec = (5/60) = 8.333333333333334\n",
      "Rec  = (5/15) = 33.333333333333336\n",
      "7600: 0.05\n",
      "Prec = (5/60) = 8.333333333333334\n",
      "Rec  = (5/15) = 33.333333333333336\n",
      "7700: 0.05\n",
      "Prec = (5/60) = 8.333333333333334\n",
      "Rec  = (5/15) = 33.333333333333336\n",
      "7800: 0.05\n",
      "Prec = (5/60) = 8.333333333333334\n",
      "Rec  = (5/15) = 33.333333333333336\n",
      "7900: 0.05\n",
      "Prec = (5/60) = 8.333333333333334\n",
      "Rec  = (5/15) = 33.333333333333336\n",
      "8000: 0.05\n",
      "Prec = (5/60) = 8.333333333333334\n",
      "Rec  = (5/15) = 33.333333333333336\n",
      "8100: 0.05\n",
      "Prec = (5/60) = 8.333333333333334\n",
      "Rec  = (5/15) = 33.333333333333336\n",
      "8200: 0.05\n",
      "Prec = (5/60) = 8.333333333333334\n",
      "Rec  = (5/15) = 33.333333333333336\n",
      "8300: 0.05\n",
      "Prec = (5/60) = 8.333333333333334\n",
      "Rec  = (5/15) = 33.333333333333336\n",
      "8400: 0.05\n",
      "Prec = (5/60) = 8.333333333333334\n",
      "Rec  = (5/15) = 33.333333333333336\n",
      "8500: 0.04\n",
      "Prec = (5/60) = 8.333333333333334\n",
      "Rec  = (5/15) = 33.333333333333336\n",
      "8600: 0.04\n",
      "Prec = (5/60) = 8.333333333333334\n",
      "Rec  = (5/15) = 33.333333333333336\n",
      "8700: 0.04\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-339-2d1b7a1f178e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0msent_placeholder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msent_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mpred_placeholder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpred_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mgold_placeholder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgold_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         })\n\u001b[1;32m     21\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from bp_pas.eval import evaluate\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "loss = srl_loss(gold_placeholder, pred_placeholder, pred_embeddings, context_rep)\n",
    "opt_op = opt.minimize(loss)\n",
    "\n",
    "num_epochs = 10000\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    for train_dict in train_dicts:\n",
    "        sent_ids, pred_ids, gold_labels = train_dict\n",
    "#        print(gold_labels.shape)\n",
    "        _, closs = sess.run([opt_op, loss], feed_dict = {\n",
    "            sent_placeholder: sent_ids,\n",
    "            pred_placeholder: pred_ids,\n",
    "            gold_placeholder: gold_labels\n",
    "        })\n",
    "        epoch_loss += closs.mean()\n",
    "    if epoch % 100 == 0:\n",
    "        decoded = [pas for pas in decode(sess, sent).pas for sent in train_data[0][:5]]\n",
    "        gold = [pas for pas in sent.pas for sent in train_data[0][:5]]\n",
    "        evaluate(decoded, gold)\n",
    "        print('{0:>4}: {1:.2f}'.format(epoch, epoch_loss))\n",
    "    \n",
    "\n",
    "#feed_dict = {sent_placeholder: sent_ids, pred_placeholder: pred_ids}\n",
    "#context_out = sess.run(context_rep, feed_dict=feed_dict)\n",
    "#print(context_out.shape)\n",
    "#out = sess.run(pred_scores, feed_dict=feed_dict)\n",
    "#print(out)\n",
    "#print(out.shape)\n",
    "#print(out[0].shape)\n",
    "\n",
    "# 1, 9, 8\n",
    "\n",
    "#want 1, 9, 1\n",
    "\n",
    "\n",
    "\n",
    "# context mat is 71, 8\n",
    "\n",
    "# pred mat is 8, 36\n",
    "\n",
    "# after mult is 71 x 36\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "\t 0\n",
      "\t 3\n",
      "\t 34\n",
      "36\n",
      "\t 0\n",
      "\t 0\n",
      "\t 25\n",
      "40\n",
      "\t 38\n",
      "\t 25\n",
      "\t 68\n",
      "46\n",
      "\t 28\n",
      "\t 36\n",
      "\t 44\n",
      "52\n",
      "\t 0\n",
      "\t 0\n",
      "\t 4\n",
      "54\n",
      "\t 0\n",
      "\t 68\n",
      "\t 0\n",
      "57\n",
      "\t 69\n",
      "\t 0\n",
      "\t 0\n",
      "63\n",
      "\t 69\n",
      "\t 0\n",
      "\t 69\n",
      "69\n",
      "\t 23\n",
      "\t 68\n",
      "\t 36\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bp_pas.ling.sent.Sentence at 0x1906d7908>"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
